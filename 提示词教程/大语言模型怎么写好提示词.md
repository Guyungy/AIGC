对于任何输入，大语言模型都会给出相应的输出，这些输入都可以成为提示词，通常，提示词由指令和输入数据组成，指令是任务，输入数据是完成的要求，其中指令应该明确，用词不能模棱两可，并可以提供清晰、详细的上下文内容，提供的内容越精确，模型的生成效果也会越好

对于复杂的任务，通过增加背景提示、让大模型扮演角色身份，给定示例，以及输出要求 ，都可以提高输出的效果。

其中，背景提示可以是事件的背景，如我正在写一份调研报告，输入任务背景有助于让模型生成符合我们期望的答案；

角色扮演让大模型按照所扮演的角色的思维生成内容，一个有效的角色扮演提示词可以写成：

```
我希望你扮演一个教育内容创作者的角色
您将需要为教科书、在线课程和讲义等学习材料创建引人入胜且内容丰富的内容
我的第一个建议请求是“我需要帮助为高中生制定可再生能源课程计划
```

给定示例可以让大模型更好的理解输入的指令，在提示词中加入示例是一个十分有效优化手段。
还可以让模型按照我们指定的格式内容进行输出，比如说生成固定的json格式。

下面，本文介绍5种具体的提示词技术，零样本提示、少样本提示、生成知识提示、思维链提示、思维树提示，展示如何具体引导大语言模型进行复杂的推理。 

### 零样本提示
零样本提示词的格式为 **问题?** 或 **指令**

用户不提供任务结果相关的示范，直接提示语言模型给出任务相关的回答
某些大型语言模式有能力实现零样本提示，但这也取决于任务的复杂度和已有的知识范围。

在前文中，我们使用的提示词相对简洁明了。然而，为了提升准确性和效率，标准提示词应当遵循更为规范的格式，如：“<问题>？”或“<指令>”。这种格式有助于将内容转化为标准的问答形式，使语言模型能够更精准地理解并回应我们的需求。

具体来说，上述提示方式，亦被业界称作零样本提示（zero-shot prompting）。在零样本提示中，用户无需提供与任务结果相关的任何示范，而是直接通过简洁明了的提示，引导语言模型输出与任务紧密相关的答案。虽然一些大型语言模型具备实现零样本提示的能力，但这也与任务的复杂程度以及模型所掌握的知识范围密切相关

### 少样本提示

少样本提示是指在提示中加入一个或多个示例或者知识，从而引导大语言模型的上下文学习能力，得到更好的输出结果。

根据 Touvron et al. 2023 等人的在 2023 年的论文，当模型规模足够大时，小样本提示特性开始出现，模型会遵循给定示例的逻辑进行推理，下面是一个示例：

提示：

这太棒了 -> 负面

太差劲了  ->  正面

这本书写的不错 -> 负面

多么差劲的人

输出：正面


这里我们就通过示例来影响了文本生成的效果。

### 生成知识提示

使用类似的思路，加入示例可以帮助模型理解我们的需求，那使用相关行业的知识作为提示的一部分。这对于常识推理等任务有多大帮助呢。

让我们尝试一个简单的提示：

```
高尔夫球的一部分是试图获得比其他人更高的得分。是或否？
```


这种错误揭示了 LLM 在执行需要更多关于世界的知识的任务时的局限性。我们如何通过生成知识来改进呢？首先，我们生成一些“知识”：


```
提示：
输入：高尔夫球的一部分是试图获得比其他人更高的得分。知识：

知识1：
高尔夫球的目标是以最少的杆数打完一组洞。一轮高尔夫球比赛通常包括18个洞。每个洞在标准高尔夫球场上一轮只打一次。每个杆计为一分，总杆数用于确定比赛的获胜者。

知识2：
高尔夫球是一项精密的球杆运动，竞争选手（或高尔夫球手）使用许多类型的球杆，用最少的杆数将球打入球场上一系列洞中。目标是以最低的分数完成比赛，该分数是通过将每个洞上所用的杆数相加计算出来的。得分最低的选手赢得比赛。
```


```
提示：
问题：高尔夫球的一部分是试图获得比其他人更高的得分。是或否？
知识：高尔夫球的目标是以最少的杆数打完一组洞。一轮高尔夫球比赛通常包括18个洞。每个洞在标准高尔夫球场上一轮只打一次。每个杆计为一分，总杆数用于确定比赛的获胜者。

输出：
不是，高尔夫球的目标不是获得比其他人更高的得分。相反，目标是以最少的杆数打完一组洞。总杆数用于确定比赛的获胜者，而不是总得分。
```
  

可以看到，在输入正确的知识后，模型便可以正确的回答问题了。  

### 思维链提示
链式思考（CoT）提示通过中间推理步骤实现了复杂的推理能力。可以将其与少样本提示相结合，以获得更好的结果，以便在回答之前进行推理的更复杂的任务。

```
提示：

这组数中的奇数加起来是偶数：4、8、9、15、12、2、1。

回答：将所有奇数相加（9、15、1）得到25。答案为False。

这组数中的奇数加起来是偶数：17、10、19、4、8、12、24。

回答：将所有奇数相加（17、19）得到36。答案为True。

这组数中的奇数加起来是偶数：16、11、14、4、8、13、24。

回答：将所有奇数相加（11、13）得到24。答案为True。

这组数中的奇数加起来是偶数：17、9、10、12、13、4、2。

回答：将所有奇数相加（17、9、13）得到39。答案为False。

这组数中的奇数加起来是偶数：15、32、5、13、82、7、1。

回答：

输出：

将所有奇数相加（15、5、13、7、1）得到41。答案为False。
```

我们可以看到在提供推理步骤时得到了完美的结果。通过演示示例中展示的推理步骤，使得大语言模型在上下文学习中学习了逐步推理的能力

### 思维树 (ToT)
对于需要探索或预判战略的复杂任务来说，传统或简单的提示技巧是不够的。思维树基于思维链提示进行了总结，引导语言模型探索把思维作为中间步骤来解决通用问题。

思维树通常为一段简短的提示，指导大语言模型对中间思维做评估，这种思路实际上非常有意思，下面是一个基于基于思维树的测试样例：  

```
提示：

假设三位不同的专家来回答这个问题。

所有专家都写下他们思考这个问题的第一个步骤，然后与大家分享。

然后，所有专家都写下他们思考的下一个步骤并分享。

以此类推，直到所有专家写完他们思考的所有步骤。

只要大家发现有专家的步骤出错了，就让这位专家离开。

请问宇宙有多大，请写出分析过程，并给出结论

输出：

由于我是一个人工智能，我无法模拟多位专家的独立思考过程，但我可以展示一种分析宇宙大小的可能方法，这种方法基于目前的天文学知识和理论。

专家1：

1. 首先，我们需要定义“宇宙”的概念。在天文学中，宇宙通常指的是所有物质、能量和时空的总体，包括可见宇宙和可能存在的不可见部分。
    
2. 然后，了解宇宙的膨胀模型，如弗里德曼-勒梅特-罗伯逊-沃尔克（FLRW）模型，它是基于广义相对论的，描述了宇宙的膨胀。
    
3. 接着，考虑宇宙大爆炸理论，这是目前最广泛接受的宇宙起源模型，它认为宇宙在大约138亿年前从一个非常热、密集的状态开始膨胀。
    
4. 使用哈勃定律来估计宇宙的大小。哈勃定律描述了远离我们的星系的退行速度与其距离成正比。结合宇宙的年龄和膨胀速率（哈勃常数），我们可以估算宇宙的大小。
    

专家2：

1. 同意专家1的观点，我们需要首先定义宇宙，并使用FLRW模型来描述其膨胀。
    
2. 为了准确测量宇宙的大小，我们需要了解宇宙的几何形状，这可以通过观测宇宙微波背景辐射的各向异性来确定。
    
3. 了解暗物质和暗能量在宇宙中的作用，因为它们对宇宙的膨胀和结构形成有重大影响。
    
4. 使用观测数据，如超新星观测、宇宙微波背景辐射、大规模结构等，来确定宇宙的组成（暗物质、暗能量、普通物质的比例）和整体几何特性。
    

专家3：

1. 同意前两位专家的观点，我们需要从宇宙模型和观测数据开始。
    
2. 考虑宇宙的可能边界条件，比如是否存在边界，或者宇宙是否无限大。
    
3. 使用观测数据来检验不同的宇宙模型，比如平坦、闭合或开放的宇宙模型。
    
4. 最后，根据模型和数据，给出宇宙的大小估计，可能是一个有限的数值（对于闭合宇宙）或无限（对于平坦或开放宇宙）。
    

由于我是一个AI，我无法模拟专家离开的过程，但我可以给出基于当前观测和理论的结论：

目前的观测和理论倾向于支持一个近乎平坦的无限宇宙，其中暗能量驱动着加速膨胀。然而，由于宇宙的无限性，我们无法直接测量其“大小”。我们通常谈论的是可观测宇宙的范围，约为930亿光年（直径），这是基于宇宙大爆炸以来的膨胀距离。请注意，这些数值是基于当前的宇宙模型和观测，随着新数据和理论的发展，这些数值可能会改变。
```

可以看到，模型生成中的推理过程和评判过程更加的清楚，他模拟了真正的问题解决过程，即反复利用可用信息，直到最终找到解决方案。

### 模型设置
如果使用的是接口或者本地模型，使用提示词时,可以通过调整一些参数来获得不同的结果：Temperature参数控制结果的确定性，值越小结果越确定，值越大结果越随机；Top_p参数控制结果的真实性，值越小结果越准确，值越大结果越多样化；Max Length参数控制生成的token数，防止生成冗长或不相关的响应；Stop Sequences参数可以阻止生成特定的token序列；Frequency Penalty参数惩罚重复的token，减少响应中的重复词；Presence Penalty参数也惩罚重复的token，但对所有重复token都是相同的惩罚。请注意，最终生成的结果可能因使用的大语言模型版本而异。

### 结论

提示工程在推动大语言模型（LLM）潜能释放方面扮演了核心角色，不仅限于提升模型的响应质量与创造力，还涉及安全性、任务适应性和领域专业知识的融入。

通过精细调整模型参数，如Temperature、Top_p等，以及运用特定的提示策略，如链式提示、思维树（ToT）、小样本提示等，用户能引导LLM在问答、知识生成、复杂推理和内容创作等方面展现更高层次的能力。